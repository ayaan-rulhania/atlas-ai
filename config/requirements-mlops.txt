# MLOps and Advanced Training Dependencies for v2.1.0
# Install these for advanced model training, evaluation, and serving
# Updated: 2026-01-03

# Parameter-Efficient Fine-Tuning
peft>=0.6.0
bitsandbytes>=0.41.0  # For QLoRA quantization

# Hyperparameter Tuning
optuna>=3.4.0
optuna-dashboard>=0.13.0  # Optional: Web dashboard for Optuna

# Model Registry and Tracking
mlflow>=2.8.0
dvc>=3.0.0  # Data version control

# Advanced Quantization
autoawq>=0.1.6  # AWQ quantization
auto-gptq>=0.5.0  # GPTQ quantization

# Speech Recognition (Whisper)
openai-whisper>=20231117
faster-whisper>=0.9.0  # Faster Whisper implementation

# Inference Servers (optional, for production)
# vllm>=0.2.0  # Uncomment if using vLLM
# tensorrt-llm>=0.5.0  # Uncomment if using TensorRT-LLM

# Additional utilities
accelerate>=0.24.0  # For distributed training
transformers>=4.35.0  # Latest transformers for model compatibility
datasets>=2.14.0  # For dataset handling
evaluate>=0.4.0  # For model evaluation metrics
safetensors>=0.4.0  # Secure model weight storage for R-series

